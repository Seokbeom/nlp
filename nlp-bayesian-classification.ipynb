{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math, sys\n",
    "#from konlpy.tag import Twitter\n",
    "class BayesianFilter1:\n",
    "    \"\"\" 베이지안 필터 \"\"\"\n",
    "    def __init__(self):\n",
    "        self.words = set() # 출현한 단어 기록\n",
    "        self.word_dict = {} # 카테고리마다의 출현 횟수 기록\n",
    "        self.category_dict = {} # 카테고리 출현 횟수 기록\n",
    "    # 형태소 분석하기 --- (※1)\n",
    "    def split(self, text):\n",
    "        return text.split()\n",
    "        results = []\n",
    "        twitter = Twitter()\n",
    "        # 단어의 기본형 사용\n",
    "        malist = twitter.pos(text, norm=True, stem=True)\n",
    "        for word in malist:\n",
    "            # 어미/조사/구두점 등은 대상에서 제외 \n",
    "            if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "                results.append(word[0])\n",
    "        return results\n",
    "    # 단어와 카테고리의 출현 횟수 세기 --- (※2)\n",
    "    def inc_word(self, word, category):\n",
    "        # 단어를 카테고리에 추가하기\n",
    "        if not category in self.word_dict:\n",
    "            self.word_dict[category] = {}\n",
    "        if not word in self.word_dict[category]:\n",
    "            self.word_dict[category][word] = 0\n",
    "        self.word_dict[category][word] += 1\n",
    "        self.words.add(word)\n",
    "    def inc_category(self, category):\n",
    "        # 카테고리 계산하기\n",
    "        if not category in self.category_dict:\n",
    "            self.category_dict[category] = 0\n",
    "        self.category_dict[category] += 1\n",
    "    \n",
    "    # 텍스트 학습하기 --- (※3)\n",
    "    def fit(self, text, category):\n",
    "        \"\"\" 텍스트 학습 \"\"\"\n",
    "        word_list = self.split(text)\n",
    "        for word in word_list:\n",
    "            self.inc_word(word, category)\n",
    "        self.inc_category(category)\n",
    "    \n",
    "    # 단어 리스트에 점수 매기기--- (※4)\n",
    "    def score(self, words, category):\n",
    "        score = math.log(self.category_prob(category))\n",
    "        for word in words:\n",
    "            score += math.log(self.word_prob(word, category))\n",
    "        return score\n",
    "    \n",
    "    # 예측하기 --- (※5)\n",
    "    def predict(self, text):\n",
    "        best_category = None\n",
    "        max_score = -sys.maxsize \n",
    "        words = self.split(text)\n",
    "        score_list = []\n",
    "        for category in self.category_dict.keys():\n",
    "            score = self.score(words, category)\n",
    "            score_list.append((category, score))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_category = category\n",
    "        return best_category, score_list\n",
    "    # 카테고리 내부의 단어 출현 횟수 구하기\n",
    "    def get_word_count(self, word, category):\n",
    "        if word in self.word_dict[category]:\n",
    "            return self.word_dict[category][word]\n",
    "        else:\n",
    "            return 0\n",
    "    # 카테고리 계산\n",
    "    def category_prob(self, category):\n",
    "        sum_categories = sum(self.category_dict.values())\n",
    "        category_v = self.category_dict[category]\n",
    "        return category_v / sum_categories\n",
    "        \n",
    "    # 카테고리 내부의 단어 출현 비율 계산 --- (※6)\n",
    "    def word_prob(self, word, category):\n",
    "        n = self.get_word_count(word, category) + 1 # ---(※6a)\n",
    "        d = sum(self.word_dict[category].values()) + len(self.words)\n",
    "        #print(sum(self.word_dict[category].values()))\n",
    "        return n / d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "결과 = 광고\n",
      "[('광고', -19.942524744665512), ('중요', -20.544606748320554)]\n",
      "{'광고': {'파격': 1, '세일': 3, '-': 1, '오늘까지만': 1, '30%': 1, '할인': 1, '쿠폰': 1, '선물': 1, '&': 1, '무료': 1, '배송': 1, '현데계': 1, '백화점': 1, '봄과': 1, '함께': 1, '찾아온': 1, '따뜻한': 1, '신제품': 1, '소식': 1, '인기': 1, '제품': 1, '기간': 1, '한정': 1}, '중요': {'오늘': 2, '일정': 1, '확인': 1, '프로젝트': 1, '진행': 1, '상황': 1, '보고': 1, '계약': 1, '잘': 1, '부탁드립니다': 1, '회의': 1, '일정이': 2, '등록되었습니다.': 1, '없습니다.': 1}}\n"
     ]
    }
   ],
   "source": [
    "bf = BayesianFilter1()\n",
    "# 텍스트 학습\n",
    "bf.fit(\"파격 세일 - 오늘까지만 30% 할인\", \"광고\")\n",
    "bf.fit(\"쿠폰 선물 & 무료 배송\", \"광고\")\n",
    "bf.fit(\"현데계 백화점 세일\", \"광고\")\n",
    "bf.fit(\"봄과 함께 찾아온 따뜻한 신제품 소식\", \"광고\")\n",
    "bf.fit(\"인기 제품 기간 한정 세일\", \"광고\")\n",
    "bf.fit(\"오늘 일정 확인\", \"중요\")\n",
    "bf.fit(\"프로젝트 진행 상황 보고\",\"중요\")\n",
    "bf.fit(\"계약 잘 부탁드립니다\",\"중요\")\n",
    "bf.fit(\"회의 일정이 등록되었습니다.\",\"중요\")\n",
    "bf.fit(\"오늘 일정이 없습니다.\",\"중요\")\n",
    "# 예측\n",
    "pre, scorelist = bf.predict(\"재고 정리 할인, 무료 배송\")\n",
    "print(\"결과 =\", pre)\n",
    "print(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math, sys\n",
    "#from konlpy.tag import Twitter\n",
    "class BayesianFilter:\n",
    "    \"\"\" 베이지안 필터 \"\"\"\n",
    "    def __init__(self):\n",
    "        self.words = set() # 출현한 단어 기록\n",
    "        self.categories = {} # 카테고리 출현 횟수 기록\n",
    "        self.cfd = _\n",
    " \n",
    "    # 텍스트 문장 학습하기 --- (※3)\n",
    "    def sfit(self, data):\n",
    "        \"\"\" 텍스트 학습 \"\"\"\n",
    "        train_data = []\n",
    "        for s, c in data:\n",
    "            for w in s.split():\n",
    "                train_data.append((c, w))\n",
    "                if c in self.categories :\n",
    "                    self.categories[c] += 1\n",
    "                else:\n",
    "                    self.categories[c] = 1\n",
    "                self.words.add(w)\n",
    "        self.cfd = nltk.ConditionalFreqDist(train_data)\n",
    "\n",
    "    # 텍스트 단어 학습하기 --- (※3)\n",
    "    def fit(self, data):\n",
    "        \"\"\" 텍스트 학습 \"\"\"\n",
    "        train_data = []\n",
    "        for w, c in data:\n",
    "            train_data.append((c, w))\n",
    "            if c in self.categories :\n",
    "                self.categories[c] += 1\n",
    "            else:\n",
    "                self.categories[c] = 1\n",
    "            self.words.add(w)\n",
    "        self.cfd = nltk.ConditionalFreqDist(train_data)\n",
    "\n",
    "    # 단어 리스트에 점수 매기기--- (※4)\n",
    "    def score(self, words, category):\n",
    "        s_category = sum(self.categories.values())         \n",
    "        score = math.log( self.categories[category] / s_category )\n",
    "        for word in words:\n",
    "            score += math.log( (self.cfd[category][word]+1) / (self.categories[category] + len(self.words)) )\n",
    "        return score\n",
    "    \n",
    "    # 예측하기 --- (※5)\n",
    "    def predict(self, text):\n",
    "        best_category = None\n",
    "        max_score = -sys.maxsize \n",
    "        words = text.split()\n",
    "        score_list = []\n",
    "\n",
    "        for category in self.categories:\n",
    "            score = self.score(words, category)\n",
    "            score_list.append((category, score))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_category = category\n",
    "        return best_category, score_list\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 = 광고\n",
      "[('광고', -19.744073805941674), ('중요', -20.792442912225134)]\n",
      "{'광고': 25, '중요': 16}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 텍스트 학습\n",
    "train = (\n",
    "(\"파격 세일 - 오늘까지만 30% 할인\", \"광고\"), \n",
    "(\"쿠폰 선물 & 무료 배송\", \"광고\"), \n",
    "(\"현데계 백화점 세일\", \"광고\"), \n",
    "(\"봄과 함께 찾아온 따뜻한 신제품 소식\", \"광고\"), \n",
    "(\"인기 제품 기간 한정 세일\", \"광고\"),\n",
    "(\"오늘 일정 확인\", \"중요\"),\n",
    "(\"프로젝트 진행 상황 보고\",\"중요\"),\n",
    "(\"계약 잘 부탁드립니다\",\"중요\"),\n",
    "(\"회의 일정이 등록되었습니다.\",\"중요\"),\n",
    "(\"오늘 일정이 없습니다.\",\"중요\"))\n",
    "\n",
    "bf = BayesianFilter()\n",
    "bf.sfit( train) # sentence fit\n",
    "# 예측\n",
    "pre, scorelist = bf.predict(\"재고 정리 할인, 무료 배송\")\n",
    "print(\"결과 =\", pre)\n",
    "print(scorelist)\n",
    "print(bf.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'religion': 39399, 'hobbies': 82345, 'romance': 70022}\n",
      "결과 = hobbies\n",
      "[('religion', -44.690389662751386), ('hobbies', -41.7446485560634), ('romance', -42.379087929010275)]\n"
     ]
    }
   ],
   "source": [
    "# 1. 기존 코드를 cfd를 사용하여 변경\n",
    "# 2. fit 함수를 train data를 한꺼번에 받아서 처리하도록 변경\n",
    "# 3. brown corpus에서 특정 카테고리의 데이터로 학습 \n",
    "# 4. lala land와 god father의 영화 시나리오를 읽어서 학습 \n",
    "# 5. wordnet으로 synset으로 학습\n",
    "# 6. lemma, stopword 처리, lower()\n",
    "# 7. wordnet.synsets\n",
    "\n",
    "from nltk.corpus import brown \n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "# raw word + lower()\n",
    "train = [ (word.lower(), genre)  for genre in ['religion','hobbies', 'romance']     for word in brown.words(categories=genre) ]\n",
    "\n",
    "# stop word removal ==> romance\n",
    "#train = [ (word, genre)  for genre in ['religion','hobbies', 'romance']     for word in brown.words(categories=genre) if word not in nltk.corpus.stopwords.words('english')]\n",
    "\n",
    "# wordnet synset\n",
    "#from nltk.corpus import wordnet as wn\n",
    "#train = [ (wn.synsets(word)[0], genre)  for genre in ['religion','hobbies', 'romance']     for word in brown.words(categories=genre) if len(wn.synsets(word)) ]\n",
    "\n",
    "# lemma\n",
    "#train = [ (wnl.lemmatize(word), genre)  for genre in ['religion','hobbies', 'romance']     for word in brown.words(categories=genre) ]\n",
    "bf = BayesianFilter()\n",
    "#bf.fit(train[:1000]+train[-1000:])\n",
    "bf.fit(train)\n",
    "# 예측\n",
    "print(bf.categories)\n",
    "pre, scorelist = bf.predict(\" go fishing with friends food \")\n",
    "print(\"결과 =\", pre)\n",
    "print(scorelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 8] nodename nor servname provided, or not known>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1318\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 936\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-cd062a3f557d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://www.imsdb.com/scripts/La-La-Land.html\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 8] nodename nor servname provided, or not known>"
     ]
    }
   ],
   "source": [
    "# 영화 시나리오 읽어서 학습 \n",
    "from urllib import request\n",
    "from nltk import word_tokenize\n",
    "url = \"http://www.imsdb.com/scripts/La-La-Land.html\"\n",
    "html = request.urlopen(url).read()\n",
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html, 'lxml').get_text()\n",
    "#raw = nltk.clean_html(html)\n",
    "tokens = word_tokenize(raw)\n",
    "\n",
    "train = [ (word, 'lala')  for word in tokens ]\n",
    "\n",
    "url = \"http://www.imsdb.com/scripts/Godfather.html\"\n",
    "html = request.urlopen(url).read()\n",
    "#from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html, 'lxml').get_text()\n",
    "#raw = nltk.clean_html(html)\n",
    "tokens = word_tokenize(raw)\n",
    "train1 = [ (word, 'godfather')  for word in tokens ]\n",
    "\n",
    "bf = BayesianFilter()\n",
    "#bf.fit(train[:1000]+train[-1000:])\n",
    "bf.fit(train+train1)\n",
    "# 예측\n",
    "print(bf.categories)\n",
    "pre, scorelist = bf.predict(\" cafe jazz la holywood\")\n",
    "print(\"결과 =\", pre)\n",
    "print(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lala': 23525, 'raiders': 33354}\n",
      "결과 = lala\n",
      "[('lala', -38.831415179102905), ('raiders', -42.9370522501272)]\n",
      "결과 = raiders\n",
      "[('lala', -31.843430396707827), ('raiders', -31.237614023744555)]\n"
     ]
    }
   ],
   "source": [
    "# 영화 local file 읽어서 학습 \n",
    "from nltk import word_tokenize\n",
    "\n",
    "with open('lalaland.txt') as f:\n",
    "    raw = f.read()\n",
    "\n",
    "tokens = word_tokenize(raw)\n",
    "train = [ (word, 'lala')  for word in tokens ]\n",
    "\n",
    "with open('raiders.txt') as f:\n",
    "    raw = f.read()\n",
    "\n",
    "tokens = word_tokenize(raw)\n",
    "train1 = [ (word, 'raiders')  for word in tokens ]\n",
    "\n",
    "bf = BayesianFilter()\n",
    "#bf.fit(train[:1000]+train[-1000:])\n",
    "bf.fit(train+train1)\n",
    "# 예측\n",
    "print(bf.categories)\n",
    "\n",
    "pre, scorelist = bf.predict(\" cafe jazz la holywood\")\n",
    "print(\"결과 =\", pre)\n",
    "print(scorelist)\n",
    "\n",
    "pre1, scorelist1 = bf.predict(\" professor treasure cave \")\n",
    "print(\"결과 =\", pre1)\n",
    "print(scorelist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 = science_fiction\n",
      "[('humor', -24.634257847275627), ('science_fiction', -24.496745933446153)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown \n",
    "\n",
    "train = [ (genre, word)  for genre in ['humor','science_fiction']     for word in brown.words(categories=genre) ]\n",
    "bf = BayesianFilter1()\n",
    "for i in train:\n",
    "    bf.fit(i[1], i[0])\n",
    "#print(train[:100]+train[-100:])\n",
    "# 예측\n",
    "pre, scorelist = bf.predict(\" with  mars space \")\n",
    "print(\"결과 =\", pre)\n",
    "print(scorelist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
